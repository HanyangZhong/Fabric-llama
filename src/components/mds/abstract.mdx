# Abstract

Choosing the correct fabric is key to meeting functional and quality demands in robotic applications for textile manufacturing, apparel production, and smart retail. This paper introduces Fabric-Llama, a multimodal robotic system integrating visual and tactile sensing with large language model-based reasoning for context-aware fabric selection. The system employs a robotic arm with visual and tactile sensors, combining supervised fine-tuning and knowledge distillation to sort and rank fabric properties accurately. We release a dataset of 200 fabric samples, which includes RGB images and synchronized tactile data with pressure readings, to encourage further research. Experimental results demonstrate that Fabric-Llama-90B surpasses baseline models, achieving state-of-the-art performance in fabric sorting and selection. 